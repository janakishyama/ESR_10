{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import re\n",
    "\n",
    "import warnings    # to avoid warning during executions\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_10_FPC23_RhoSa.csv',\n",
       " '_11_FPC24_SkeMa_1.csv',\n",
       " '_12_FPC24_SkeMa_2.csv',\n",
       " '_16_FPC23_NaCho.csv',\n",
       " '_1_FPC13_ChCal_1.csv',\n",
       " '_2_FPC13_ChCal_2.csv',\n",
       " '_3_FPC13_ThalaPs.csv',\n",
       " '_4_FPC14_ChaMu.csv',\n",
       " '_5_FPC14_RhoSa.csv',\n",
       " '_6_FPC14_ThalaPs.csv',\n",
       " '_7_FPC21_ChaMu.csv',\n",
       " '_8_FPC21_TeChu.csv',\n",
       " '_9_FPC22_DiaLut.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all the file names into a list (files in the pbr data folder)\n",
    "os.getcwd()\n",
    "_dir_path_hour = '../../../dataExport/cumulativeDATA/Hour'\n",
    "raw_data_hour = os.listdir(_dir_path_hour)\n",
    "raw_data_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_12_FPC24_SkeMa_2.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_hour = raw_data_hour[2]\n",
    "filename_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database connection with mariaDB using SQL Alchemy\n",
    "def dbConn_sqlAlc():\n",
    "    database_username = 'root'\n",
    "    database_password = 'password'\n",
    "    database_ip       = '127.0.0.1:3306'\n",
    "    database_name     = 'data_dashboard'\n",
    "    database_connection = sqlalchemy.create_engine('mariadb+mariadbconnector://{0}:{1}@{2}/{3}'.\n",
    "                                               format(database_username, database_password, \n",
    "                                                      database_ip, database_name))\n",
    "    return database_connection\n",
    "\n",
    "# # database connection with mariaDB using pymysql package\n",
    "def dBCon_Maria():\n",
    "    connection = pymysql.connect(host='localhost',\n",
    "                            user='root',\n",
    "                            password='password',\n",
    "                            db='data_dashboard')\n",
    "    return connection\n",
    "\n",
    "\n",
    "# connection = dBCon_Maria()\n",
    "# cursor=connection.cursor()                                            \n",
    "# database_connection = dbConn_sqlAlc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set trial no, species_id and unit number for processing data\n",
    "def set_varables(trial_no):\n",
    "    database_connection = dbConn_sqlAlc()\n",
    "    tbl_lookup = pd.read_sql(\"SELECT * FROM tbl_pbr_lookup WHERE instance = ?\", database_connection, params=[trial_no])\n",
    "    species_id = int(tbl_lookup['species'])\n",
    "    trial_no = int(tbl_lookup['instance'])\n",
    "    unit_id = int(tbl_lookup['unit'])\n",
    "    return species_id, trial_no, unit_id\n",
    "\n",
    "\n",
    "# Preprocessing the data setting/ adding values and data types\n",
    "def pbr_preProcess(sum_hour_raw, trial_no):\n",
    "    variable_list = set_varables(trial_no)\n",
    "    pbr_raw_tmp1 = sum_hour_raw.copy()\n",
    "    pbr_raw_tmp1.insert(loc=3, column='trial_no', value=variable_list[1])\n",
    "    pbr_raw_tmp1.insert(loc=4, column='species', value=variable_list[0])      \n",
    "    return(\n",
    "    pbr_raw_tmp1\n",
    "    .assign(unit = variable_list[2])\n",
    "    .replace('Empty', pd.np.nan)\n",
    "    .replace('inf', pd.np.nan)\n",
    "    .replace([np.inf, -np.inf], pd.np.nan)\n",
    "    .astype({'primary_key':'int64', '_timeString':'datetime64[ns]','unit': 'int16','D_Algae':'float32', 'D_CD':'float32', 'D_CO2':'float32', 'D_PAR':'float32', 'D_eff':'float32', 'D_feed':'float32', 'D_g':'float32', 'D_harvest':'float32'})\n",
    "    )\n",
    "\n",
    "\n",
    "# Missing Value imputation using interpolation - spline\n",
    "def missingValue_imputation(sum_hour_cleaned):\n",
    "    sum_hour_cleaned_indexed = sum_hour_cleaned.set_index('_timeString')\n",
    "    null_cols = sum_hour_cleaned_indexed.columns[sum_hour_cleaned_indexed.isnull().any()].tolist()\n",
    "    for pbr_col in null_cols:\n",
    "        sum_hour_cleaned_indexed[pbr_col]=sum_hour_cleaned_indexed[pbr_col].interpolate(option='spline')\n",
    "\n",
    "    sum_hour_cleaned_indexed = sum_hour_cleaned_indexed.reset_index(level=0)\n",
    "    new_col = list(sum_hour_cleaned.columns)\n",
    "    sum_hour_cleaned_indexed=sum_hour_cleaned_indexed[new_col]\n",
    "    return sum_hour_cleaned_indexed\n",
    "\n",
    "\n",
    "# exporting the preprocessed data into db pbr\n",
    "def pbr_exporttoDB(sumHour_preprocessed):\n",
    "    connection = dBCon_Maria()\n",
    "    cursor=connection.cursor()      \n",
    "    cols = \"`,`\".join([str(i) for i in sumHour_preprocessed.columns.tolist()])\n",
    "    for i,row in sumHour_preprocessed.iterrows():\n",
    "        sql = \"INSERT INTO `tbl_cumulative_per_hour` (`\" +cols + \"`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "        cursor.execute(sql, tuple(row))\n",
    "\n",
    "    connection.commit()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is exported\n"
     ]
    }
   ],
   "source": [
    "# load content of the export_list into list split by new line\n",
    "# data = [line.strip() for line in open(\"exported_list.txt\", 'r')]\n",
    "with open('./exported_list.txt') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "if (filename_hour not in lines):\n",
    "    trial_no = re.findall(r'\\d+', filename_hour)\n",
    "    trial_no = int(trial_no[0])\n",
    "    file_path=  os.path.join(_dir_path_hour, filename_hour)\n",
    "    sumHour_rawDF = pd.read_csv(file_path, sep=',')\n",
    "    sum_hour_cleaned = pbr_preProcess(sumHour_rawDF, trial_no)\n",
    "    sumHour_preprocessed = missingValue_imputation(sum_hour_cleaned)\n",
    "    try:\n",
    "        export_status = pbr_exporttoDB(sumHour_preprocessed)\n",
    "        file1 = open(\"exported_list.txt\", \"a\")\n",
    "        file1.write(\"\\n\")     \n",
    "        file1.write(filename_hour)\n",
    "        file1.close()\n",
    "        print('file is exported')\n",
    "    except Exception as e: print(e)\n",
    "\n",
    "else:\n",
    "    print('data is present in the db - check and very the trial number in tbl_pbr_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Exported Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_connection = dbConn_sqlAlc()\n",
    "tbl_logdata = pd.read_sql('SELECT * FROM tbl_cumulative_per_hour where trial_no = ?', database_connection, params=[trial_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_logdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumHour_rawDF.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8fd34dff8cbc24a9527e9490242a6d6fdd745231ebdb737d8653779b044c6d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
